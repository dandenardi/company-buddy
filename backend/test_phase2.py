"""
Test script for Phase 2: Semantic Chunking

This script tests the new semantic chunking features:
1. Structure detection (titles, sections)
2. Paragraph-aware chunking
3. Overlap between chunks
4. Content hash generation
5. Deduplication
"""

from app.services.semantic_chunker import SemanticChunker


def test_basic_chunking():
    """Test basic semantic chunking."""
    print("\n" + "="*60)
    print("TEST 1: Basic Semantic Chunking")
    print("="*60)
    
    chunker = SemanticChunker(max_chunk_size=500, overlap_size=100)
    
    text = """
INTRODU√á√ÉO

Este √© um documento de teste para validar o chunking sem√¢ntico.
O sistema deve detectar esta se√ß√£o como um t√≠tulo.

SE√á√ÉO 1: POL√çTICA DE F√âRIAS

Os colaboradores t√™m direito a 30 dias de f√©rias por ano.
As f√©rias podem ser divididas em at√© 3 per√≠odos.
O primeiro per√≠odo n√£o pode ser inferior a 14 dias.

SE√á√ÉO 2: BENEF√çCIOS

A empresa oferece os seguintes benef√≠cios:
- Vale refei√ß√£o
- Vale transporte
- Plano de sa√∫de
- Plano odontol√≥gico

Todos os benef√≠cios s√£o concedidos ap√≥s o per√≠odo de experi√™ncia.
    """
    
    chunks_with_meta = chunker.chunk_text(text.strip())
    
    print(f"‚úÖ Generated {len(chunks_with_meta)} chunks")
    
    for i, (chunk_text, metadata) in enumerate(chunks_with_meta):
        print(f"\n--- Chunk {i+1} ---")
        print(f"Section: {metadata.get('section_title', 'N/A')}")
        print(f"Hash: {metadata['content_hash'][:16]}...")
        print(f"Chars: {metadata['char_count']}, Words: {metadata['word_count']}")
        print(f"Text preview: {chunk_text[:100]}...")
    
    return chunks_with_meta


def test_overlap():
    """Test that chunks have overlap."""
    print("\n" + "="*60)
    print("TEST 2: Chunk Overlap")
    print("="*60)
    
    chunker = SemanticChunker(max_chunk_size=200, overlap_size=50)
    
    text = "Lorem ipsum dolor sit amet. " * 50  # Long text
    
    chunks_with_meta = chunker.chunk_text(text)
    chunks = [c[0] for c in chunks_with_meta]
    
    print(f"‚úÖ Generated {len(chunks)} chunks from long text")
    
    # Check for overlap
    has_overlap = False
    for i in range(len(chunks) - 1):
        chunk1_end = chunks[i][-50:]
        chunk2_start = chunks[i+1][:50]
        
        # Check if there's any common text
        if any(word in chunk2_start for word in chunk1_end.split()[-5:]):
            has_overlap = True
            print(f"‚úÖ Overlap detected between chunk {i+1} and {i+2}")
            break
    
    if has_overlap:
        print("‚úÖ Overlap feature working correctly")
    else:
        print("‚ö†Ô∏è  No overlap detected (might be expected for this text)")


def test_deduplication():
    """Test content hash generation for deduplication."""
    print("\n" + "="*60)
    print("TEST 3: Content Hash & Deduplication")
    print("="*60)
    
    chunker = SemanticChunker()
    
    text1 = "Este √© um texto de teste para deduplica√ß√£o."
    text2 = "Este √© um texto de teste para deduplica√ß√£o."  # Identical
    text3 = "Este √© um texto diferente."
    
    chunks1 = chunker.chunk_text(text1)
    chunks2 = chunker.chunk_text(text2)
    chunks3 = chunker.chunk_text(text3)
    
    hash1 = chunks1[0][1]['content_hash']
    hash2 = chunks2[0][1]['content_hash']
    hash3 = chunks3[0][1]['content_hash']
    
    print(f"Hash 1: {hash1[:16]}...")
    print(f"Hash 2: {hash2[:16]}...")
    print(f"Hash 3: {hash3[:16]}...")
    
    if hash1 == hash2:
        print("‚úÖ Identical texts produce identical hashes")
    else:
        print("‚ùå Identical texts should have same hash!")
    
    if hash1 != hash3:
        print("‚úÖ Different texts produce different hashes")
    else:
        print("‚ùå Different texts should have different hashes!")


def test_section_detection():
    """Test section title detection."""
    print("\n" + "="*60)
    print("TEST 4: Section Detection")
    print("="*60)
    
    chunker = SemanticChunker()
    
    text = """
T√çTULO EM MAI√öSCULAS

Este par√°grafo est√° sob o t√≠tulo.

Subt√≠tulo com dois pontos:

Este par√°grafo est√° sob o subt√≠tulo.
    """
    
    chunks_with_meta = chunker.chunk_text(text.strip())
    
    sections_found = set()
    for chunk_text, metadata in chunks_with_meta:
        if metadata.get('section_title'):
            sections_found.add(metadata['section_title'])
    
    print(f"‚úÖ Detected {len(sections_found)} sections:")
    for section in sections_found:
        print(f"   - {section}")
    
    if len(sections_found) > 0:
        print("‚úÖ Section detection working")
    else:
        print("‚ö†Ô∏è  No sections detected")


def main():
    """Run all tests."""
    print("="*60)
    print("PHASE 2 SEMANTIC CHUNKING TESTS")
    print("="*60)
    
    test_basic_chunking()
    test_overlap()
    test_deduplication()
    test_section_detection()
    
    print("\n" + "="*60)
    print("TESTS COMPLETED")
    print("="*60)
    print("\nüìã Next steps:")
    print("1. Run migration: python migrate_phase2.py")
    print("2. Upload a test document")
    print("3. Check logs for 'Gerando chunks sem√¢nticos'")
    print("4. Verify chunks have better structure")


if __name__ == "__main__":
    main()
